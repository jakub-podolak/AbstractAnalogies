{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2df4cdf5-7705-4569-8108-f0f36c0d97bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e57ba430-0703-4577-a209-8594d4e2526d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(data):\n",
    "    if 'parsed_answer' not in data.columns or 'correct_answer' not in data.columns:\n",
    "        raise ValueError(\"DataFrame must contain 'parsed_answer' and 'correct_answer' columns\")\n",
    "    \n",
    "    correct_predictions = (data['parsed_answer'] == data['correct_answer']).sum()\n",
    "    total_predictions = data.shape[0]\n",
    "    \n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e21daf1d-b109-4cf8-b9a9-9f85c12f844a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = os.listdir('../results/story_far_all_prompts/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25321e6-3e55-4b41-86cf-8b25e2d47594",
   "metadata": {},
   "source": [
    "# LLAMA3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45601a7a-e794-477e-a69b-30eca8d072f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c75c25ea-3b47-47bd-96b3-340d86b3c953",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama3_results = sorted([res for res in all_results if 'llama3' in res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "92d72e93-e286-4983-b5c8-aacc2e34b3dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['story_analogies_far_llama3_prompt_templates-story_analogies-1_basic_prompt_not_forced-1.csv',\n",
       " 'story_analogies_far_llama3_prompt_templates-story_analogies-1_basic_prompt_not_forced-2.csv',\n",
       " 'story_analogies_far_llama3_prompt_templates-story_analogies-1_basic_prompt_not_forced-3.csv',\n",
       " 'story_analogies_far_llama3_prompt_templates-story_analogies-2_basic_prompt_forced-1.csv',\n",
       " 'story_analogies_far_llama3_prompt_templates-story_analogies-2_basic_prompt_forced-2.csv',\n",
       " 'story_analogies_far_llama3_prompt_templates-story_analogies-2_basic_prompt_forced-3.csv',\n",
       " 'story_analogies_far_llama3_prompt_templates-story_analogies-3_cot-1.csv',\n",
       " 'story_analogies_far_llama3_prompt_templates-story_analogies-3_cot-2.csv',\n",
       " 'story_analogies_far_llama3_prompt_templates-story_analogies-3_cot-3.csv',\n",
       " 'story_analogies_far_llama3_prompt_templates-story_analogies-4_cot_structured-1.csv',\n",
       " 'story_analogies_far_llama3_prompt_templates-story_analogies-4_cot_structured-2.csv',\n",
       " 'story_analogies_far_llama3_prompt_templates-story_analogies-4_cot_structured-3.csv']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama3_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "59582040-946e-4a91-83e4-0578e3f02dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_prompt_info(filenames):\n",
    "    extracted_info = []\n",
    "    for filename in filenames:\n",
    "        match = re.search(r'story_analogies-\\d+_(.*?)-(\\d+)\\.csv', filename)\n",
    "        if match:\n",
    "            prompt_type = match.group(1)\n",
    "            run_number = match.group(2)\n",
    "            extracted_info.append((prompt_type, run_number))\n",
    "    return extracted_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "73d10820-4cc3-48f6-ac48-0f9fe29dc762",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_final = []\n",
    "\n",
    "for res_file in llama3_results:\n",
    "    data = pd.read_csv('../results/story_far_all_prompts/' + res_file)[['parsed_answer', 'correct_answer']]\n",
    "    (prompt_type, prompt_number) = extract_prompt_info([res_file])[0]\n",
    "\n",
    "    accuracy = calculate_accuracy(data)\n",
    "    results_final.append({'prompt_type': prompt_type, 'prompt_number': prompt_number, 'accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4bd33fa2-63dc-446f-af12-dab658270eb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_type</th>\n",
       "      <th>prompt_number</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>basic_prompt_not_forced</td>\n",
       "      <td>1</td>\n",
       "      <td>0.638889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>basic_prompt_not_forced</td>\n",
       "      <td>2</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>basic_prompt_not_forced</td>\n",
       "      <td>3</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basic_prompt_forced</td>\n",
       "      <td>1</td>\n",
       "      <td>0.527778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>basic_prompt_forced</td>\n",
       "      <td>2</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>basic_prompt_forced</td>\n",
       "      <td>3</td>\n",
       "      <td>0.694444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cot</td>\n",
       "      <td>1</td>\n",
       "      <td>0.638889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cot</td>\n",
       "      <td>2</td>\n",
       "      <td>0.638889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cot</td>\n",
       "      <td>3</td>\n",
       "      <td>0.638889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cot_structured</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cot_structured</td>\n",
       "      <td>2</td>\n",
       "      <td>0.638889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cot_structured</td>\n",
       "      <td>3</td>\n",
       "      <td>0.694444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                prompt_type prompt_number  accuracy\n",
       "0   basic_prompt_not_forced             1  0.638889\n",
       "1   basic_prompt_not_forced             2  0.722222\n",
       "2   basic_prompt_not_forced             3  0.666667\n",
       "3       basic_prompt_forced             1  0.527778\n",
       "4       basic_prompt_forced             2  0.722222\n",
       "5       basic_prompt_forced             3  0.694444\n",
       "6                       cot             1  0.638889\n",
       "7                       cot             2  0.638889\n",
       "8                       cot             3  0.638889\n",
       "9            cot_structured             1  0.666667\n",
       "10           cot_structured             2  0.638889\n",
       "11           cot_structured             3  0.694444"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results_df = pd.DataFrame(results_final)\n",
    "final_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ae8b715c-2bf3-4cd2-9072-f901cb291ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prompt_type</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>basic_prompt_forced</th>\n",
       "      <td>0.648148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>basic_prompt_not_forced</th>\n",
       "      <td>0.675926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cot</th>\n",
       "      <td>0.638889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cot_structured</th>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         accuracy\n",
       "prompt_type                      \n",
       "basic_prompt_forced      0.648148\n",
       "basic_prompt_not_forced  0.675926\n",
       "cot                      0.638889\n",
       "cot_structured           0.666667"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results_df.groupby(by='prompt_type').agg({'accuracy': 'mean'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229df4a8-36b6-4b74-995a-fd7158d5e7ae",
   "metadata": {},
   "source": [
    "# Majority voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "36ab586a-4774-405a-a471-9194656afe94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3f48a7cd-cf1c-4e74-82d3-854549fdb5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_vote(*args):\n",
    "    return [Counter(votes).most_common(1)[0][0] for votes in zip(*args)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bf858978-a175-47f5-825f-d1c9f0a2e7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "story_analogies_far_llama3_prompt_templates-story_analogies-1_basic_prompt_not_forced-1.csv story_analogies_far_llama3_prompt_templates-story_analogies-1_basic_prompt_not_forced-2.csv story_analogies_far_llama3_prompt_templates-story_analogies-1_basic_prompt_not_forced-3.csv\n",
      "story_analogies_far_llama3_prompt_templates-story_analogies-2_basic_prompt_forced-1.csv story_analogies_far_llama3_prompt_templates-story_analogies-2_basic_prompt_forced-2.csv story_analogies_far_llama3_prompt_templates-story_analogies-2_basic_prompt_forced-3.csv\n",
      "story_analogies_far_llama3_prompt_templates-story_analogies-3_cot-1.csv story_analogies_far_llama3_prompt_templates-story_analogies-3_cot-2.csv story_analogies_far_llama3_prompt_templates-story_analogies-3_cot-3.csv\n",
      "story_analogies_far_llama3_prompt_templates-story_analogies-4_cot_structured-1.csv story_analogies_far_llama3_prompt_templates-story_analogies-4_cot_structured-2.csv story_analogies_far_llama3_prompt_templates-story_analogies-4_cot_structured-3.csv\n"
     ]
    }
   ],
   "source": [
    "results_majority = []\n",
    "\n",
    "for i in range(0, len(llama3_results), 3):\n",
    "    prompt_1 = llama3_results[i]\n",
    "    prompt_2 = llama3_results[i + 1]\n",
    "    prompt_3 = llama3_results[i + 2]\n",
    "    print(prompt_1, prompt_2, prompt_3)\n",
    "\n",
    "    data_1 = pd.read_csv('../results/story_far_all_prompts/' + prompt_1)[['parsed_answer', 'correct_answer']]\n",
    "    data_2 = pd.read_csv('../results/story_far_all_prompts/' + prompt_2)[['parsed_answer', 'correct_answer']]\n",
    "    data_3 = pd.read_csv('../results/story_far_all_prompts/' + prompt_3)[['parsed_answer', 'correct_answer']]\n",
    "\n",
    "    data_1['parsed_answer'] = majority_vote(data_1['parsed_answer'], data_2['parsed_answer'], data_3['parsed_answer'])\n",
    "\n",
    "    (prompt_type, prompt_number) = extract_prompt_info([prompt_1])[0]\n",
    "\n",
    "    accuracy = calculate_accuracy(data_1)\n",
    "    results_majority.append({'prompt_type': prompt_type, 'accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2fe09ad0-56d8-41e9-b62a-4771cf68f216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_type</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>basic_prompt_not_forced</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>basic_prompt_forced</td>\n",
       "      <td>0.694444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cot</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cot_structured</td>\n",
       "      <td>0.638889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               prompt_type  accuracy\n",
       "0  basic_prompt_not_forced  0.666667\n",
       "1      basic_prompt_forced  0.694444\n",
       "2                      cot  0.666667\n",
       "3           cot_structured  0.638889"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results_majority)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaefdf1-b8d6-456f-a385-26df17ca86ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
